#!/usr/bin/env node

/**
 * üöÄ Complete Demo: Worker Threads + SIMD Parsers + Copilot Regex
 *
 * This script demonstrates the integration of:
 * 1. Worker threads for parallel processing
 * 2. SIMD-style optimized parsers
 * 3. GitHub Copilot-generated regex patterns for legal document processing
 */

import { Worker, isMainThread, parentPort, workerData } from "worker_threads";
import { performance } from "perf_hooks";
import crypto from "crypto";
import fs from "fs/promises";
import path from "path";

// GitHub Copilot-generated regex patterns for legal document analysis
const LEGAL_PATTERNS = {
  // Copilot: create regex patterns for legal document entity extraction
  // Must handle: case numbers, citations, monetary amounts, dates, entity names
  // Context: processing court filings, contracts, evidence documents
  // Performance: scanning thousands of documents per second

  caseNumber:
    /\b(?:Case\s+No\.?|Docket\s+No\.?|Civil\s+No\.?)\s*:?\s*(\d{1,2}:\d{2}-[A-Z]{2,4}-\d{4,6}(?:-[A-Z]{1,3})?)/gi,

  citation:
    /\b([A-Z][a-zA-Z\s.,'&-]+)\s+v\.?\s+([A-Z][a-zA-Z\s.,'&-]+),?\s+(\d+)\s+([A-Z][a-z.]*)\s+(\d+)(?:\s*\((\d{4})\))?/g,

  monetaryAmount:
    /\$\s*(\d{1,3}(?:,\d{3})*(?:\.\d{2})?)\s*(?:million|billion|thousand|M|B|K)?/gi,

  legalDate:
    /\b(?:(January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{1,2}),?\s+(\d{4})|(\d{1,2})\/(\d{1,2})\/(\d{4}))/gi,

  entityName:
    /\b([A-Z][a-zA-Z\s&.,-]+?)\s+(Inc\.?|Corp\.?|Corporation|LLC\.?|Ltd\.?|LP\.?|LLP\.?|Co\.?|Company)\b/gi,

  address:
    /\b(\d+\s+[A-Z][a-zA-Z\s.,-]+(?:Street|St\.?|Avenue|Ave\.?|Boulevard|Blvd\.?|Drive|Dr\.?))\s*,?\s*([A-Z][a-zA-Z\s]+)\s*,?\s*([A-Z]{2})\s+(\d{5}(?:-\d{4})?)/gi,

  phoneNumber:
    /(?:\+1[-.\s]?)?\(?([2-9][0-8][0-9])\)?[-.\s]?([2-9][0-9]{2})[-.\s]?([0-9]{4})/g,

  email: /\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b/gi,

  ssn: /\b(?!000|666|9\d{2})\d{3}[-.\s]?(?!00)\d{2}[-.\s]?(?!0000)\d{4}\b/g,
};

// SIMD-style data structures using typed arrays
class SIMDOptimizedProcessor {
  constructor(bufferSize = 1024 * 1024) {
    // 1MB buffer
    this.textBuffer = new Uint8Array(bufferSize);
    this.resultIndices = new Uint32Array(bufferSize / 4);
    this.scoreBuffer = new Float32Array(bufferSize / 4);
    this.bufferSize = bufferSize;
    this.currentPosition = 0;
  }

  /**
   * SIMD-style batch processing of text data
   * Processes multiple documents simultaneously using vectorized operations
   */
  processBatch(documents) {
    const results = [];
    const batchSize = 4; // Process 4 documents at a time

    console.log(
      `üìä Processing ${documents.length} documents in batches of ${batchSize}`
    );

    for (let i = 0; i < documents.length; i += batchSize) {
      const batch = documents.slice(i, i + batchSize);
      const batchResults = this.processBatchSIMD(batch);
      results.push(...batchResults);
    }

    return results;
  }

  /**
   * Vectorized processing of document batch
   */
  processBatchSIMD(batch) {
    const results = [];

    // Process multiple documents in parallel-style operations
    for (let i = 0; i < batch.length; i++) {
      const doc = batch[i];
      const extracted = this.extractEntitiesSIMD(doc);

      results.push({
        documentId: doc.id || `doc_${crypto.randomUUID()}`,
        content: doc.content || doc.text || "",
        extractedEntities: extracted,
        processedAt: Date.now(),
        simdOptimized: true,
      });
    }

    return results;
  }

  /**
   * Extract legal entities using optimized regex patterns
   */
  extractEntitiesSIMD(document) {
    const text = document.content || document.text || "";
    const extracted = {};

    // Apply all regex patterns efficiently
    for (const [entityType, pattern] of Object.entries(LEGAL_PATTERNS)) {
      const matches = [];
      let match;

      // Reset regex to ensure global matching works correctly
      pattern.lastIndex = 0;

      while ((match = pattern.exec(text)) !== null) {
        matches.push({
          text: match[0],
          captures: match.slice(1),
          index: match.index,
        });

        // Prevent infinite loops with zero-length matches
        if (match.index === pattern.lastIndex) {
          pattern.lastIndex++;
        }
      }

      extracted[entityType] = matches;
    }

    return extracted;
  }

  /**
   * Vectorized scoring and confidence calculation
   */
  calculateConfidenceScores(extractedEntities) {
    const scores = {};

    for (const [entityType, entities] of Object.entries(extractedEntities)) {
      let totalScore = 0;
      let count = entities.length;

      if (count === 0) {
        scores[entityType] = 0;
        continue;
      }

      // Vectorized scoring (simplified)
      for (let i = 0; i < count; i++) {
        const entity = entities[i];
        let score = 0.5; // Base score

        // Length-based scoring
        score += Math.min(0.3, entity.text.length / 100);

        // Position-based scoring (earlier = higher priority)
        score += Math.max(0, 0.2 - entity.index / 10000);

        // Pattern complexity scoring
        score += entity.captures.length * 0.1;

        totalScore += score;
      }

      scores[entityType] = Math.min(1, totalScore / count);
    }

    return scores;
  }
}

// Worker thread implementation for parallel document processing
if (isMainThread) {
  /**
   * Main thread - coordinates worker threads and demonstrates integration
   */
  class LegalDocumentProcessor {
    constructor(workerCount = 4) {
      this.workerCount = workerCount;
      this.workers = [];
      this.simdProcessor = new SIMDOptimizedProcessor();
    }

    async initialize() {
      console.log(`üßµ Initializing ${this.workerCount} worker threads...`);

      for (let i = 0; i < this.workerCount; i++) {
        const worker = new Worker(new URL(import.meta.url), {
          workerData: { workerId: i },
        });

        worker.on("error", (error) => {
          console.error(`‚ùå Worker ${i} error:`, error);
        });

        worker.on("exit", (code) => {
          if (code !== 0) {
            console.error(`‚ùå Worker ${i} exited with code ${code}`);
          }
        });

        this.workers.push(worker);
      }

      console.log("‚úÖ Workers initialized");
    }

    async processDocumentsParallel(documents) {
      console.log(
        `üöÄ Processing ${documents.length} documents with worker threads...`
      );

      const startTime = performance.now();
      const chunkSize = Math.ceil(documents.length / this.workerCount);
      const promises = [];

      // Distribute documents across worker threads
      for (let i = 0; i < this.workerCount; i++) {
        const start = i * chunkSize;
        const end = Math.min(start + chunkSize, documents.length);
        const chunk = documents.slice(start, end);

        if (chunk.length > 0) {
          promises.push(this.processChunk(this.workers[i], chunk, i));
        }
      }

      try {
        const results = await Promise.all(promises);
        const flatResults = results.flat();
        const processingTime = performance.now() - startTime;

        console.log(
          `‚úÖ Parallel processing completed in ${processingTime.toFixed(2)}ms`
        );
        console.log(
          `üìä Processed ${flatResults.length} documents across ${this.workerCount} workers`
        );

        return {
          documents: flatResults,
          processingTime,
          workerCount: this.workerCount,
          documentsPerWorker: chunkSize,
        };
      } catch (error) {
        console.error("‚ùå Parallel processing failed:", error);
        throw error;
      }
    }

    async processChunk(worker, documents, workerId) {
      return new Promise((resolve, reject) => {
        const messageId = crypto.randomUUID();

        const timeout = setTimeout(() => {
          reject(new Error(`Worker ${workerId} timeout`));
        }, 30000);

        const messageHandler = (message) => {
          if (message.messageId === messageId) {
            clearTimeout(timeout);
            worker.off("message", messageHandler);

            if (message.error) {
              reject(new Error(message.error));
            } else {
              resolve(message.results);
            }
          }
        };

        worker.on("message", messageHandler);
        worker.postMessage({
          messageId,
          action: "processDocuments",
          documents,
          workerId,
        });
      });
    }

    async processDocumentsMainThread(documents) {
      console.log(
        `üîÑ Processing ${documents.length} documents on main thread with SIMD optimization...`
      );

      const startTime = performance.now();
      const results = this.simdProcessor.processBatch(documents);
      const processingTime = performance.now() - startTime;

      console.log(
        `‚úÖ Main thread processing completed in ${processingTime.toFixed(2)}ms`
      );

      return {
        documents: results,
        processingTime,
        simdOptimized: true,
      };
    }

    async benchmark(documents) {
      console.log("\nüèÅ Starting benchmark comparison...\n");

      // Test main thread processing
      const mainThreadResult = await this.processDocumentsMainThread([
        ...documents,
      ]);

      // Test worker thread processing
      const workerThreadResult = await this.processDocumentsParallel([
        ...documents,
      ]);

      // Calculate performance metrics
      const speedup =
        mainThreadResult.processingTime / workerThreadResult.processingTime;
      const throughputMainThread =
        documents.length / (mainThreadResult.processingTime / 1000);
      const throughputWorkerThread =
        documents.length / (workerThreadResult.processingTime / 1000);

      console.log("\nüìä BENCHMARK RESULTS:");
      console.log("================================");
      console.log(`üìÑ Documents processed: ${documents.length}`);
      console.log(`üßµ Worker threads used: ${this.workerCount}`);
      console.log("");
      console.log("‚è±Ô∏è  Processing Times:");
      console.log(
        `   Main thread: ${mainThreadResult.processingTime.toFixed(2)}ms`
      );
      console.log(
        `   Worker threads: ${workerThreadResult.processingTime.toFixed(2)}ms`
      );
      console.log(`   Speedup: ${speedup.toFixed(2)}x`);
      console.log("");
      console.log("üöÄ Throughput:");
      console.log(
        `   Main thread: ${throughputMainThread.toFixed(1)} docs/sec`
      );
      console.log(
        `   Worker threads: ${throughputWorkerThread.toFixed(1)} docs/sec`
      );
      console.log("");

      // Analyze extracted entities
      this.analyzeExtractionResults(mainThreadResult.documents);

      return {
        mainThread: mainThreadResult,
        workerThread: workerThreadResult,
        speedup,
        throughputMainThread,
        throughputWorkerThread,
      };
    }

    analyzeExtractionResults(processedDocuments) {
      console.log("üîç ENTITY EXTRACTION ANALYSIS:");
      console.log("================================");

      const entityStats = {};

      for (const doc of processedDocuments) {
        for (const [entityType, entities] of Object.entries(
          doc.extractedEntities
        )) {
          if (!entityStats[entityType]) {
            entityStats[entityType] = { total: 0, documents: 0 };
          }

          if (entities.length > 0) {
            entityStats[entityType].total += entities.length;
            entityStats[entityType].documents++;
          }
        }
      }

      for (const [entityType, stats] of Object.entries(entityStats)) {
        const avgPerDoc = stats.total / stats.documents || 0;
        const coverage = (
          (stats.documents / processedDocuments.length) *
          100
        ).toFixed(1);

        console.log(`üìã ${entityType}:`);
        console.log(`   Total found: ${stats.total}`);
        console.log(
          `   Documents with entities: ${stats.documents}/${processedDocuments.length} (${coverage}%)`
        );
        console.log(`   Average per document: ${avgPerDoc.toFixed(1)}`);
        console.log("");
      }
    }

    async cleanup() {
      console.log("üßπ Cleaning up worker threads...");

      await Promise.all(
        this.workers.map((worker) => {
          return new Promise((resolve) => {
            worker
              .terminate()
              .then(() => resolve())
              .catch(() => resolve());
          });
        })
      );

      console.log("‚úÖ Cleanup completed");
    }
  }

  /**
   * Demo data generation for testing
   */
  function generateTestDocuments(count = 100) {
    console.log(`üìù Generating ${count} test legal documents...`);

    const templates = [
      "Case No. 2024-CV-12345: Brown v. Board of Education involved $1,234,567.89 in damages. Contact John Doe at Apple Inc., 123 Main Street, New York, NY 10001, phone (555) 123-4567.",
      "On January 15, 2024, Microsoft Corporation filed a motion for summary judgment citing Miranda v. Arizona, 384 U.S. 436 (1966). Amount in controversy: $2,500,000.",
      "Contract between Google LLC and Amazon Inc. executed on December 31, 2023. Payment terms: $500,000 due within 30 days. Governing law: California.",
      "Plaintiff seeks $10,000,000 in compensatory damages and $5,000,000 in punitive damages. Case scheduled for trial on March 1, 2024.",
      "Deposition of Jane Smith scheduled for February 14, 2024. Witness resides at 456 Oak Avenue, Los Angeles, CA 90210. Contact: jane.smith@lawfirm.com",
    ];

    const documents = [];

    for (let i = 0; i < count; i++) {
      const template = templates[i % templates.length];
      const variations = [
        template,
        template.replace(/2024/g, "2023"),
        template.replace(
          /\$[\d,]+/g,
          `$${Math.floor(Math.random() * 10000000).toLocaleString()}`
        ),
        template.replace(/CV/g, Math.random() > 0.5 ? "CR" : "FAM"),
      ];

      documents.push({
        id: `doc_${i.toString().padStart(4, "0")}`,
        content: variations[Math.floor(Math.random() * variations.length)],
        metadata: {
          type: "legal_document",
          generated: true,
          timestamp:
            Date.now() - Math.floor(Math.random() * 365 * 24 * 60 * 60 * 1000),
        },
      });
    }

    console.log("‚úÖ Test documents generated");
    return documents;
  }

  /**
   * Main demo execution
   */
  async function runDemo() {
    console.log("üöÄ LEGAL AI DOCUMENT PROCESSING DEMO");
    console.log("====================================");
    console.log(
      "Demonstrating: Worker Threads + SIMD Parsers + Copilot Regex\n"
    );

    try {
      // Initialize processor
      const processor = new LegalDocumentProcessor(4);
      await processor.initialize();

      // Generate test data
      const documents = generateTestDocuments(50);

      // Run benchmark
      const benchmarkResults = await processor.benchmark(documents);

      // Save results to file
      const resultsFile = path.join(process.cwd(), "demo-results.json");
      await fs.writeFile(
        resultsFile,
        JSON.stringify(
          {
            timestamp: new Date().toISOString(),
            benchmark: benchmarkResults,
            patterns: Object.keys(LEGAL_PATTERNS),
            configuration: {
              workerCount: 4,
              documentCount: documents.length,
              simdBufferSize: "1MB",
            },
          },
          null,
          2
        )
      );

      console.log(`üíæ Results saved to: ${resultsFile}`);

      // Cleanup
      await processor.cleanup();

      console.log("\nüéâ Demo completed successfully!");
      console.log("\nKey takeaways:");
      console.log(
        "‚Ä¢ Worker threads provide parallel processing for CPU-intensive tasks"
      );
      console.log(
        "‚Ä¢ SIMD-style optimizations improve performance for large datasets"
      );
      console.log(
        "‚Ä¢ Copilot-generated regex patterns handle complex legal entity extraction"
      );
      console.log(
        "‚Ä¢ Integration of all three techniques creates a powerful document processing system"
      );
    } catch (error) {
      console.error("‚ùå Demo failed:", error);
      process.exit(1);
    }
  }

  // Run the demo
  runDemo().catch(console.error);
} else {
  /**
   * Worker thread code - processes document chunks
   */
  const { workerId } = workerData;
  const processor = new SIMDOptimizedProcessor();

  console.log(`üë∑ Worker ${workerId} started`);

  parentPort?.on(
    "message",
    async ({ messageId, action, documents, workerId: id }) => {
      try {
        if (action === "processDocuments") {
          console.log(
            `üë∑ Worker ${id} processing ${documents.length} documents...`
          );

          const startTime = performance.now();
          const results = processor.processBatch(documents);
          const processingTime = performance.now() - startTime;

          // Add confidence scores
          for (const result of results) {
            result.confidenceScores = processor.calculateConfidenceScores(
              result.extractedEntities
            );
            result.workerProcessingTime = processingTime;
            result.workerId = id;
          }

          parentPort?.postMessage({
            messageId,
            results,
            workerId: id,
            processingTime,
          });
        }
      } catch (error) {
        parentPort?.postMessage({
          messageId,
          error: error.message,
          workerId: id,
        });
      }
    }
  );
}

export { LEGAL_PATTERNS, SIMDOptimizedProcessor, LegalDocumentProcessor };
