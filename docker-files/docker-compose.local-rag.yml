version: '3.8'

services:
  # Local Vector Database (Qdrant)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: local-qdrant
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - ./qdrant_storage:/qdrant/storage
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
    restart: unless-stopped
    networks:
      - local-rag

  # Local Redis for Caching
  redis:
    image: redis:7-alpine
    container_name: local-redis
    ports:
      - "6379:6379"
    volumes:
      - ./redis_data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped
    networks:
      - local-rag

  # Local Embedding Service (SentenceTransformer)
  embedding-service:
    build:
      context: ./services/embedding-service
      dockerfile: Dockerfile
    container_name: local-embedding-service
    ports:
      - "8001:8001"
    environment:
      - QDRANT_URL=http://qdrant:6333
      - REDIS_URL=redis://redis:6379
      - MODEL_NAME=all-MiniLM-L6-v2
      - DEVICE=cuda  # Change to 'cpu' if no GPU
      - BATCH_SIZE=32
    volumes:
      - ./model_cache:/app/model_cache
    depends_on:
      - qdrant
      - redis
    restart: unless-stopped
    networks:
      - local-rag
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  # Local RAG API Service
  rag-api:
    build:
      context: ./services/rag-api
      dockerfile: Dockerfile
    container_name: local-rag-api
    ports:
      - "8000:8000"
    environment:
      - EMBEDDING_SERVICE_URL=http://embedding-service:8001
      - QDRANT_URL=http://qdrant:6333
      - REDIS_URL=redis://redis:6379
      - RAG_COLLECTION_NAME=legal_documents
    depends_on:
      - qdrant
      - redis
      - embedding-service
    restart: unless-stopped
    networks:
      - local-rag

networks:
  local-rag:
    driver: bridge

volumes:
  qdrant_storage:
  redis_data:
  model_cache: