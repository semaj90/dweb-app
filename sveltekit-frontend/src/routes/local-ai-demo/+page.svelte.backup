<!-- Enhanced RAG Demo with Local LLM Support -->
<script lang="ts">
  import AskAI from "$lib/components/ai/AskAI.svelte";
  import { aiService } from "$lib/services/ai-service";
  import { tauriLLM, type LocalModel } from "$lib/services/tauri-llm";
  import {
    AlertTriangle,
    Brain,
    CheckCircle,
    Cloud,
    Cpu,
    Database,
    Search,
    Shield,
    Zap,
  } from "lucide-svelte";
  import { onMount } from "svelte";

  interface SystemStatus {
    database: boolean;
    qdrant: boolean;
    embeddings: boolean;
    vectorSearch: boolean;
    tauriLLM: boolean;
    localModels: LocalModel[];
  }

  let systemStatus: SystemStatus = {
    database: false,
    qdrant: false,
    embeddings: false,
    vectorSearch: false,
    tauriLLM: false,
    localModels: [],
  };

  let isLoadingStatus = true;
  let testQuery = "";
  interface TestResults {
    error?: string;
    data?: unknown;
    results?: Array<{
      title: string;
      content: string;
      score: number;
      source: string;
      type: string;
    }>;
    executionTime?: number;
    source?: string;
  }
  
  let testResults: TestResults | null = null;
  let isTestingSearch = false;
  let selectedProvider: "auto" | "local" | "cloud" = "auto";
  let legalAnalysisText = "";
  
  interface AnalysisResults {
    error?: string;
    classification?: {
      category: string;
      confidence: number;
    };
    keyEntities: Array<{
      text: string;
      type: string;
      confidence: number;
    }>;
  }
  
  let analysisResults: AnalysisResults | null = null;
  let isAnalyzing = false;

  // Demo queries optimized for legal domain
  const legalDemoQueries = [
    "What are the key elements required to establish a breach of contract?",
    "Explain the difference between criminal and civil liability",
    "What constitutes admissible evidence in federal court?",
    "How does attorney-client privilege protect confidential communications?",
    "What are the requirements for a valid search warrant?",
    "Explain the burden of proof in criminal vs civil cases",
  ];

  onMount(async () => {
    await checkSystemStatus();
  });

  async function checkSystemStatus() {
    isLoadingStatus = true;

    try {
      // Check database connection
      const dbResponse = await fetch("/api/search/cases?limit=1");
      systemStatus.database = dbResponse.ok;

      // Check Qdrant
      const qdrantResponse = await fetch("/api/qdrant");
      systemStatus.qdrant = qdrantResponse.ok;

      // Check embeddings
      const embeddingResponse = await fetch("/api/embeddings");
      systemStatus.embeddings = embeddingResponse.ok;

      // Check vector search
      const vectorResponse = await fetch("/api/search/vector", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          query: "test",
          options: { limit: 1 },
        }),
      });
      systemStatus.vectorSearch = vectorResponse.ok;

      // Check Tauri LLM capabilities
      await tauriLLM.initialize();
      systemStatus.tauriLLM = tauriLLM.isAvailable();
      systemStatus.localModels = tauriLLM.getAvailableModels();
    } catch (error) {
      console.error("Status check failed:", error);
    } finally {
      isLoadingStatus = false;
    }
  }

  async function testVectorSearch() {
    if (!testQuery.trim()) return;

    isTestingSearch = true;
    testResults = null;

    try {
      const response = await fetch("/api/search/vector", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          query: testQuery,
          options: {
            limit: 5,
            threshold: 0.5,
            searchType: "hybrid",
            provider: selectedProvider,
          },
        }),
      });

      if (response.ok) {
        const data = await response.json();
        testResults = data.data;
      } else {
        const error = await response.json();
        testResults = { error: error.error };
      }
    } catch (error) {
      testResults = { error: "Network error" };
    } finally {
      isTestingSearch = false;
    }
  }

  async function analyzeLegalDocument() {
    if (!legalAnalysisText.trim()) return;

    isAnalyzing = true;
    analysisResults = null;

    try {
      // Use enhanced AI service for legal analysis
      await aiService.initialize();

      if (systemStatus.tauriLLM) {
        // Use local legal analysis
        analysisResults =
          await aiService.analyzeLegalDocument(legalAnalysisText);
      } else {
        // Fallback to cloud analysis
        const response = await fetch("/api/ai/ask", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({
            query: `Analyze this legal document and provide classification, key points, and risk assessment: ${legalAnalysisText}`,
            options: {
              provider: "auto",
              legalContext: true,
              maxTokens: 800,
            },
          }),
        });

        if (response.ok) {
          const data = await response.json();
          analysisResults = {
            classification: { category: "document", confidence: 0.8 },
            summary: data.data.answer,
            keyEntities: ["Legal Document"],
            riskAssessment: "Analysis completed using cloud AI",
          };
        }
      }
    } catch (error) {
      analysisResults = {
        error: error instanceof Error ? error.message : "Unknown error",
      };
    } finally {
      isAnalyzing = false;
    }
  }

  async function loadLocalModel(modelId: string) {
    try {
      await tauriLLM.loadModel(modelId);
      await checkSystemStatus(); // Refresh status
    } catch (error) {
      console.error("Failed to load model:", error);
    }
  }

  function handleAIResponse(event: CustomEvent) {
    console.log("AI Response:", event.detail);
  }

  function handleReferenceClick(event: CustomEvent) {
    console.log("Reference clicked:", event.detail);
  }

  function getStatusIcon(status: boolean) {
    return status ? CheckCircle : AlertTriangle;
  }

  function getStatusColor(status: boolean) {
    return status ? "text-green-600" : "text-red-600";
  }

  function getProviderIcon(provider: string) {
    switch (provider) {
      case "local":
        return Cpu;
      case "cloud":
        return Cloud;
      default:
        return Brain;
    }
  }
</script>

<svelte:head>
  <title>Enhanced RAG Demo - Local AI + Cloud Integration</title>
</svelte:head>

<div class="mx-auto px-4 max-w-7xl">
  <div class="mx-auto px-4 max-w-7xl">
    <!-- Header -->
    <div class="mx-auto px-4 max-w-7xl">
      <h1 class="mx-auto px-4 max-w-7xl">
        Enhanced RAG System Demo
      </h1>
      <p class="mx-auto px-4 max-w-7xl">
        Production-ready Retrieval-Augmented Generation with <strong
          >Local Rust LLMs</strong
        >, Legal-BERT models, PostgreSQL + pgvector, Qdrant, and intelligent
        fallback mechanisms.
      </p>
      <div class="mx-auto px-4 max-w-7xl">
        <span
          class="mx-auto px-4 max-w-7xl"
        >
          <Shield class="mx-auto px-4 max-w-7xl" />
          Privacy-First Local AI
        </span>
        <span
          class="mx-auto px-4 max-w-7xl"
        >
          <Cpu class="mx-auto px-4 max-w-7xl" />
          Rust + Legal-BERT
        </span>
        <span
          class="mx-auto px-4 max-w-7xl"
        >
          <Cloud class="mx-auto px-4 max-w-7xl" />
          Cloud Fallback
        </span>
      </div>
    </div>

    <!-- System Status -->
    <div class="mx-auto px-4 max-w-7xl">
      <div class="mx-auto px-4 max-w-7xl">
        <div class="mx-auto px-4 max-w-7xl">
          <h2 class="mx-auto px-4 max-w-7xl">
            Enhanced System Status
          </h2>
          <button
            on:click={() => checkSystemStatus()}
            class="mx-auto px-4 max-w-7xl"
            disabled={isLoadingStatus}
          >
            {isLoadingStatus ? "Checking..." : "Refresh"}
          </button>
        </div>

        <div class="mx-auto px-4 max-w-7xl">
          <div class="mx-auto px-4 max-w-7xl">
            <Database class="mx-auto px-4 max-w-7xl" />
            <div>
              <p class="mx-auto px-4 max-w-7xl">Database</p>
              <p class="mx-auto px-4 max-w-7xl">
                {systemStatus.database ? "Connected" : "Offline"}
              </p>
            </div>
          </div>

          <div class="mx-auto px-4 max-w-7xl">
            <Zap class="mx-auto px-4 max-w-7xl" />
            <div>
              <p class="mx-auto px-4 max-w-7xl">Qdrant</p>
              <p class="mx-auto px-4 max-w-7xl">
                {systemStatus.qdrant ? "Ready" : "Unavailable"}
              </p>
            </div>
          </div>

          <div class="mx-auto px-4 max-w-7xl">
            <Brain class="mx-auto px-4 max-w-7xl" />
            <div>
              <p class="mx-auto px-4 max-w-7xl">Embeddings</p>
              <p class="mx-auto px-4 max-w-7xl">
                {systemStatus.embeddings ? "Active" : "Disabled"}
              </p>
            </div>
          </div>

          <div class="mx-auto px-4 max-w-7xl">
            <Search
              class="mx-auto px-4 max-w-7xl"
            />
            <div>
              <p class="mx-auto px-4 max-w-7xl">Vector Search</p>
              <p class="mx-auto px-4 max-w-7xl">
                {systemStatus.vectorSearch ? "Operational" : "Error"}
              </p>
            </div>
          </div>

          <div
            class="mx-auto px-4 max-w-7xl"
          >
            <Cpu class="mx-auto px-4 max-w-7xl" />
            <div>
              <p class="mx-auto px-4 max-w-7xl">Local LLM</p>
              <p class="mx-auto px-4 max-w-7xl">
                {systemStatus.tauriLLM ? "Available" : "Not Available"}
              </p>
            </div>
          </div>
        </div>

        <!-- Local Models Status -->
        {#if systemStatus.tauriLLM && systemStatus.localModels.length > 0}
          <div class="mx-auto px-4 max-w-7xl">
            <h3 class="mx-auto px-4 max-w-7xl">
              Local AI Models
            </h3>
            <div class="mx-auto px-4 max-w-7xl">
              {#each systemStatus.localModels as model}
                <div class="mx-auto px-4 max-w-7xl">
                  <div class="mx-auto px-4 max-w-7xl">
                    <h4 class="mx-auto px-4 max-w-7xl">{model.name}</h4>
                    <span
                      class="mx-auto px-4 max-w-7xl"
                    >
                      {model.isLoaded ? "Loaded" : "Available"}
                    </span>
                  </div>
                  <div class="mx-auto px-4 max-w-7xl">
                    <p><span class="mx-auto px-4 max-w-7xl">Type:</span> {model.type}</p>
                    <p>
                      <span class="mx-auto px-4 max-w-7xl">Domain:</span>
                      {model.domain}
                    </p>
                    <p>
                      <span class="mx-auto px-4 max-w-7xl">Architecture:</span>
                      {model.architecture}
                    </p>
                    {#if model.dimensions}
                      <p>
                        <span class="mx-auto px-4 max-w-7xl">Dimensions:</span>
                        {model.dimensions}
                      </p>
                    {/if}
                  </div>
                  {#if !model.isLoaded}
                    <button
                      on:click={() => loadLocalModel(model.id)}
                      class="mx-auto px-4 max-w-7xl"
                    >
                      Load Model
                    </button>
                  {/if}
                </div>
              {/each}
            </div>
          </div>
        {/if}
      </div>
    </div>

    <!-- Main Demo Area -->
    <div class="mx-auto px-4 max-w-7xl">
      <!-- AI Assistant -->
      <div class="mx-auto px-4 max-w-7xl">
        <div class="mx-auto px-4 max-w-7xl">
          <div class="mx-auto px-4 max-w-7xl">
            <h3 class="mx-auto px-4 max-w-7xl">
              Enhanced AI Legal Assistant
            </h3>
            <p class="mx-auto px-4 max-w-7xl">
              Ask questions using local Legal-BERT models or cloud LLMs with
              automatic fallback.
            </p>
          </div>

          <div class="mx-auto px-4 max-w-7xl">
            <!-- Provider Selection -->
            <div class="mx-auto px-4 max-w-7xl">
              <label
                for="ai-provider-select"
                class="mx-auto px-4 max-w-7xl"
                >AI Provider</label
              >
              <div class="mx-auto px-4 max-w-7xl">
                <button
                  class="mx-auto px-4 max-w-7xl"
                  on:click={() => (selectedProvider = "auto")}
                >
                  <Brain class="mx-auto px-4 max-w-7xl" />
                  Auto
                </button>
                <button
                  class="mx-auto px-4 max-w-7xl"
                  on:click={() => (selectedProvider = "local")}
                  disabled={!systemStatus.tauriLLM}
                >
                  <Cpu class="mx-auto px-4 max-w-7xl" />
                  Local Only
                </button>
                <button
                  class="mx-auto px-4 max-w-7xl"
                  on:click={() => (selectedProvider = "cloud")}
                >
                  <Cloud class="mx-auto px-4 max-w-7xl" />
                  Cloud Only
                </button>
              </div>
            </div>

            <AskAI
              placeholder="Ask about legal procedures, cases, or evidence..."
              showReferences={true}
              enableVoiceInput={true}
              maxHeight="400px"
              on:response={handleAIResponse}
              on:referenceClicked={handleReferenceClick}
            />
          </div>
        </div>

        <!-- Legal Demo Queries -->
        <div class="mx-auto px-4 max-w-7xl">
          <h4 class="mx-auto px-4 max-w-7xl">
            Legal Domain Sample Questions:
          </h4>
          <div class="mx-auto px-4 max-w-7xl">
            {#each legalDemoQueries as query}
              <button
                class="mx-auto px-4 max-w-7xl"
                on:click={() => (testQuery = query)}
              >
                "{query}"
              </button>
            {/each}
          </div>
        </div>
      </div>

      <!-- Legal Document Analysis & Vector Search -->
      <div class="mx-auto px-4 max-w-7xl">
        <!-- Document Analysis -->
        <div class="mx-auto px-4 max-w-7xl">
          <div class="mx-auto px-4 max-w-7xl">
            <h3 class="mx-auto px-4 max-w-7xl">
              Legal Document Analysis
            </h3>
            <p class="mx-auto px-4 max-w-7xl">
              Analyze legal documents using local Legal-BERT models for
              classification and risk assessment.
            </p>
          </div>

          <div class="mx-auto px-4 max-w-7xl">
            <textarea
              bind:value={legalAnalysisText}
              placeholder="Paste a legal document excerpt for analysis..."
              class="mx-auto px-4 max-w-7xl"
            ></textarea>

            <button
              on:click={() => analyzeLegalDocument()}
              disabled={!legalAnalysisText.trim() || isAnalyzing}
              class="mx-auto px-4 max-w-7xl"
            >
              {isAnalyzing ? "Analyzing..." : "Analyze Document"}
            </button>

            {#if analysisResults}
              <div class="mx-auto px-4 max-w-7xl">
                {#if analysisResults.error}
                  <div class="mx-auto px-4 max-w-7xl">
                    <strong>Error:</strong>
                    {analysisResults.error}
                  </div>
                {:else}
                  <div class="mx-auto px-4 max-w-7xl">
                    {#if analysisResults.classification}
                      <div>
                        <h5 class="mx-auto px-4 max-w-7xl">
                          Classification:
                        </h5>
                        <p class="mx-auto px-4 max-w-7xl">
                          {analysisResults.classification.category}
                          ({Math.round(
                            analysisResults.classification.confidence * 100
                          )}% confidence)
                        </p>
                      </div>
                    {/if}

                    {#if analysisResults.summary}
                      <div>
                        <h5 class="mx-auto px-4 max-w-7xl">Summary:</h5>
                        <p class="mx-auto px-4 max-w-7xl">
                          {analysisResults.summary}
                        </p>
                      </div>
                    {/if}

                    {#if analysisResults.keyEntities}
                      <div>
                        <h5 class="mx-auto px-4 max-w-7xl">Key Entities:</h5>
                        <div class="mx-auto px-4 max-w-7xl">
                          {#each analysisResults.keyEntities.slice(0, 5) as entity}
                            <span
                              class="mx-auto px-4 max-w-7xl"
                            >
                              {entity}
                            </span>
                          {/each}
                        </div>
                      </div>
                    {/if}

                    {#if analysisResults.riskAssessment}
                      <div>
                        <h5 class="mx-auto px-4 max-w-7xl">
                          Risk Assessment:
                        </h5>
                        <p class="mx-auto px-4 max-w-7xl">
                          {analysisResults.riskAssessment}
                        </p>
                      </div>
                    {/if}
                  </div>
                {/if}
              </div>
            {/if}
          </div>
        </div>

        <!-- Vector Search Test -->
        <div class="mx-auto px-4 max-w-7xl">
          <div class="mx-auto px-4 max-w-7xl">
            <h3 class="mx-auto px-4 max-w-7xl">
              Vector Search Test
            </h3>
            <p class="mx-auto px-4 max-w-7xl">
              Test vector similarity search with hybrid local/cloud embedding
              generation.
            </p>
          </div>

          <div class="mx-auto px-4 max-w-7xl">
            <div class="mx-auto px-4 max-w-7xl">
              <input
                bind:value={testQuery}
                placeholder="Enter search query..."
                class="mx-auto px-4 max-w-7xl"
              />
              <button
                on:click={() => testVectorSearch()}
                disabled={!testQuery.trim() || isTestingSearch}
                class="mx-auto px-4 max-w-7xl"
              >
                {isTestingSearch ? "Searching..." : "Search"}
              </button>
            </div>

            {#if testResults}
              <div class="mx-auto px-4 max-w-7xl">
                {#if testResults.error}
                  <div class="mx-auto px-4 max-w-7xl">
                    <strong>Error:</strong>
                    {testResults.error}
                  </div>
                {:else}
                  <div class="mx-auto px-4 max-w-7xl">
                    <div class="mx-auto px-4 max-w-7xl">
                      Found {testResults.results?.length || 0} results in {testResults.executionTime ||
                        0}ms (Source: {testResults.source || "unknown"})
                    </div>

                    {#if testResults.results && testResults.results.length > 0}
                      {#each testResults.results as result}
                        <div
                          class="mx-auto px-4 max-w-7xl"
                        >
                          <div class="mx-auto px-4 max-w-7xl">
                            <h5 class="mx-auto px-4 max-w-7xl">
                              {result.title}
                            </h5>
                            <div class="mx-auto px-4 max-w-7xl">
                              <span class="mx-auto px-4 max-w-7xl">
                                {Math.round(result.score * 100)}% match
                              </span>
                              <svelte:component
                                this={getProviderIcon(result.source)}
                                class="mx-auto px-4 max-w-7xl"
                              />
                            </div>
                          </div>
                          <p class="mx-auto px-4 max-w-7xl">
                            {result.content.substring(0, 200)}...
                          </p>
                          <div class="mx-auto px-4 max-w-7xl">
                            <span>Type: {result.type}</span>
                            <span>Source: {result.source}</span>
                          </div>
                        </div>
                      {/each}
                    {:else}
                      <p class="mx-auto px-4 max-w-7xl">No results found.</p>
                    {/if}
                  </div>
                {/if}
              </div>
            {/if}
          </div>
        </div>
      </div>
    </div>

    <!-- Architecture Information -->
    <div class="mx-auto px-4 max-w-7xl">
      <h3 class="mx-auto px-4 max-w-7xl">
        Enhanced RAG Architecture
      </h3>
      <div class="mx-auto px-4 max-w-7xl">
        <div>
          <h4 class="mx-auto px-4 max-w-7xl">Local AI (Rust)</h4>
          <ul class="mx-auto px-4 max-w-7xl">
            <li>• Legal-BERT embeddings</li>
            <li>• Document classification</li>
            <li>• Privacy-first processing</li>
            <li>• Offline capabilities</li>
          </ul>
        </div>
        <div>
          <h4 class="mx-auto px-4 max-w-7xl">Vector Databases</h4>
          <ul class="mx-auto px-4 max-w-7xl">
            <li>• PostgreSQL + pgvector</li>
            <li>• Qdrant for advanced search</li>
            <li>• HNSW indexing</li>
            <li>• Metadata filtering</li>
          </ul>
        </div>
        <div>
          <h4 class="mx-auto px-4 max-w-7xl">Cloud Fallbacks</h4>
          <ul class="mx-auto px-4 max-w-7xl">
            <li>• OpenAI embeddings</li>
            <li>• GPT-3.5/4 chat</li>
            <li>• Ollama local LLMs</li>
            <li>• Intelligent routing</li>
          </ul>
        </div>
        <div>
          <h4 class="mx-auto px-4 max-w-7xl">Performance</h4>
          <ul class="mx-auto px-4 max-w-7xl">
            <li>• Redis caching</li>
            <li>• IndexedDB storage</li>
            <li>• Batch processing</li>
            <li>• Memory optimization</li>
          </ul>
        </div>
      </div>
    </div>

    <!-- Setup Instructions -->
    <div class="mx-auto px-4 max-w-7xl">
      <h3 class="mx-auto px-4 max-w-7xl">
        Setup Instructions
      </h3>
      <div class="mx-auto px-4 max-w-7xl">
        <p><strong>1. Start services:</strong> <code>npm run db:start</code></p>
        <p>
          <strong>2. Initialize vector search:</strong>
          <code>npm run vector:init</code>
        </p>
        <p>
          <strong>3. Set up Tauri (optional):</strong> See
          <code>TAURI_RUST_SETUP.md</code>
        </p>
        <p>
          <strong>4. Configure environment:</strong> Set API keys in
          <code>.env</code>
        </p>
        <p>
          <strong>5. Test local models:</strong> Load legal-BERT models for offline
          AI
        </p>
      </div>
    </div>
  </div>
</div>

<style>
  code {
    font-family: "Courier New", monospace;
    background: #f5f5f5;
    padding: 2px 4px;
    border-radius: 3px;
  }
</style>
