# DEFINITIVE PHASE 3+4 DOCKER COMPOSE - PRODUCTION READY
# Features: Advanced RAG + Data Management + Event Streaming + TTS
# All passwords standardized: LegalRAG2024!

version: "3.8"

services:
  # PostgreSQL with pgvector for document embeddings (Phase 3+4)
  postgres:
    image: pgvector/pgvector:pg16
    container_name: legal-postgres-phase34
    environment:
      POSTGRES_DB: legal_ai_phase34
      POSTGRES_USER: legal_admin
      POSTGRES_PASSWORD: LegalRAG2024!
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    ports:
      - "5432:5432"
    volumes:
      - postgres_phase34:/var/lib/postgresql/data
      - ./database:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U legal_admin -d legal_ai_phase34"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    command: >
      -c shared_buffers=1GB
      -c effective_cache_size=4GB
      -c work_mem=16MB
      -c maintenance_work_mem=256MB
      -c random_page_cost=1.1
      -c seq_page_cost=1.0
      -c effective_io_concurrency=200
      -c wal_buffers=16MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
    restart: unless-stopped
    networks:
      - legal-ai-phase34

  # Redis for caching and session management (Phase 3+4)
  redis:
    image: redis:7-alpine
    container_name: legal-redis-phase34
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 1gb --maxmemory-policy allkeys-lru
    volumes:
      - redis_phase34:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - legal-ai-phase34

  # RabbitMQ for event streaming (Phase 4)
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: legal-rabbitmq-phase34
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: legal_admin
      RABBITMQ_DEFAULT_PASS: LegalRAG2024!
    volumes:
      - rabbitmq_phase34:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    networks:
      - legal-ai-phase34

  # Neo4j for graph relationships (Phase 4)
  neo4j:
    image: neo4j:5.15-community
    container_name: legal-neo4j-phase34
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      NEO4J_AUTH: neo4j/LegalRAG2024!
      NEO4J_PLUGINS: '["apoc"]'
      NEO4J_dbms_memory_heap_max__size: 1G
      NEO4J_dbms_memory_pagecache_size: 512M
      NEO4J_dbms_security_procedures_unrestricted: apoc.*
    volumes:
      - neo4j_phase34:/data
      - neo4j_logs_phase34:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7474/"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    restart: unless-stopped
    networks:
      - legal-ai-phase34

  # Qdrant for vector similarity search (Phase 3)
  qdrant:
    image: qdrant/qdrant:v1.7.0
    container_name: legal-qdrant-phase34
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant_phase34:/qdrant/storage
    environment:
      QDRANT__SERVICE__HTTP_PORT: 6333
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__LOG_LEVEL: INFO
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    networks:
      - legal-ai-phase34

  # Ollama for local LLM inference (Phase 3)
  ollama:
    image: ollama/ollama:latest
    container_name: legal-ollama-phase34
    ports:
      - "11434:11434"
    volumes:
      - ollama_phase34:/root/.ollama
      - ./models:/models:ro
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_MAX_LOADED_MODELS=2
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/version"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - legal-ai-phase34

  # TTS service for text-to-speech (Phase 3+4)
  tts-service:
    build: ./tts-service
    container_name: legal-tts-phase34
    ports:
      - "10200:10200"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:10200/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - legal-ai-phase34
    tmpfs:
      - /tmp
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    # Uncomment if TTS will depend on these in the future
    # depends_on:
    #   - rabbitmq
    #   - redis

volumes:
  postgres_phase34:
    driver: local
  redis_phase34:
    driver: local
  rabbitmq_phase34:
    driver: local
  neo4j_phase34:
    driver: local
  neo4j_logs_phase34:
    driver: local
  qdrant_phase34:
    driver: local
  ollama_phase34:
    driver: local

networks:
  legal-ai-phase34:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16
