// Database Migration Runner
// Production-ready database migration and validation system

import { drizzle } from 'drizzle-orm/postgres-js';
import { migrate } from 'drizzle-orm/postgres-js/migrator';
import postgres from 'postgres';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';

const __dirname = path.dirname(fileURLToPath(import.meta.url));

interface MigrationResult {
  success: boolean;
  migrationsRun: number;
  errors: string[];
  duration: number;
}

interface ValidationResult {
  valid: boolean;
  checks: {
    tablesExist: boolean;
    indexesExist: boolean;
    extensionsEnabled: boolean;
    dataIntegrity: boolean;
  };
  errors: string[];
}

class DatabaseMigrationRunner {
  private connectionString: string;
  private client: postgres.Sql;
  private db: any;

  constructor() {
    this.connectionString = process.env.DATABASE_URL || 
      `postgresql://${process.env.DB_USER || 'postgres'}:${process.env.DB_PASSWORD || 'postgres'}@${process.env.DB_HOST || 'localhost'}:${process.env.DB_PORT || 5432}/${process.env.DB_NAME || 'legal_ai'}`;
    
    this.client = postgres(this.connectionString, {
      max: 1, // Single connection for migrations
      ssl: process.env.NODE_ENV === 'production' ? 'require' : false
    });
    
    this.db = drizzle(this.client);
  }

  /**
   * Run all pending migrations
   */
  async runMigrations(): Promise<MigrationResult> {
    const startTime = Date.now();
    const result: MigrationResult = {
      success: false,
      migrationsRun: 0,
      errors: [],
      duration: 0
    };

    try {
      console.log('üîÑ Starting database migrations...');

      // Check if database exists and is accessible
      await this.validateConnection();

      // Run Drizzle migrations
      const migrationsPath = path.join(__dirname, '../drizzle');
      console.log(`üìÅ Migrations directory: ${migrationsPath}`);

      await migrate(this.db, { migrationsFolder: migrationsPath });

      // Run additional SQL migrations if needed
      await this.runCustomMigrations();

      result.success = true;
      result.migrationsRun = 1; // Placeholder - in real implementation, count actual migrations
      console.log('‚úÖ Database migrations completed successfully');

    } catch (error: any) {
      console.error('‚ùå Migration failed:', error);
      result.errors.push(error.message);
    } finally {
      result.duration = Date.now() - startTime;
    }

    return result;
  }

  /**
   * Validate database schema and setup
   */
  async validateDatabase(): Promise<ValidationResult> {
    const result: ValidationResult = {
      valid: false,
      checks: {
        tablesExist: false,
        indexesExist: false,
        extensionsEnabled: false,
        dataIntegrity: false
      },
      errors: []
    };

    try {
      console.log('üîç Validating database schema...');

      // Check if required tables exist
      result.checks.tablesExist = await this.validateTables();
      
      // Check if required indexes exist
      result.checks.indexesExist = await this.validateIndexes();
      
      // Check if required extensions are enabled
      result.checks.extensionsEnabled = await this.validateExtensions();
      
      // Check data integrity
      result.checks.dataIntegrity = await this.validateDataIntegrity();

      result.valid = Object.values(result.checks).every(check => check);

      if (result.valid) {
        console.log('‚úÖ Database validation passed');
      } else {
        console.log('‚ö†Ô∏è Database validation failed');
      }

    } catch (error: any) {
      console.error('‚ùå Database validation error:', error);
      result.errors.push(error.message);
    }

    return result;
  }

  /**
   * Create database if it doesn't exist
   */
  async createDatabase(): Promise<boolean> {
    try {
      const dbName = process.env.DB_NAME || 'legal_ai';
      const adminConnectionString = this.connectionString.replace(`/${dbName}`, '/postgres');
      const adminClient = postgres(adminConnectionString, { max: 1 });

      console.log(`üèóÔ∏è Creating database: ${dbName}`);

      try {
        await adminClient`CREATE DATABASE ${adminClient(dbName)}`;
        console.log(`‚úÖ Database ${dbName} created successfully`);
      } catch (error: any) {
        if (error.message.includes('already exists')) {
          console.log(`‚ÑπÔ∏è Database ${dbName} already exists`);
        } else {
          throw error;
        }
      }

      await adminClient.end();
      return true;

    } catch (error: any) {
      console.error('‚ùå Failed to create database:', error);
      return false;
    }
  }

  /**
   * Setup test database for testing
   */
  async setupTestDatabase(): Promise<boolean> {
    try {
      const testDbName = (process.env.DB_NAME || 'legal_ai') + '_test';
      const baseConnectionString = this.connectionString.replace(/\/[^\/]+$/, '');
      const testConnectionString = `${baseConnectionString}/${testDbName}`;

      console.log(`üß™ Setting up test database: ${testDbName}`);

      // Create test database
      const adminClient = postgres(baseConnectionString + '/postgres', { max: 1 });
      
      try {
        await adminClient`DROP DATABASE IF EXISTS ${adminClient(testDbName)}`;
        await adminClient`CREATE DATABASE ${adminClient(testDbName)}`;
      } catch (error: any) {
        console.warn('‚ö†Ô∏è Test database setup warning:', error.message);
      }

      await adminClient.end();

      // Run migrations on test database
      const testClient = postgres(testConnectionString, { max: 1 });
      const testDb = drizzle(testClient);

      const migrationsPath = path.join(__dirname, '../drizzle');
      await migrate(testDb, { migrationsFolder: migrationsPath });

      await testClient.end();

      console.log('‚úÖ Test database setup completed');
      return true;

    } catch (error: any) {
      console.error('‚ùå Test database setup failed:', error);
      return false;
    }
  }

  /**
   * Reset database (drop and recreate all tables)
   */
  async resetDatabase(): Promise<boolean> {
    try {
      console.log('üóëÔ∏è Resetting database...');

      const tables = [
        'system_logs',
        'embeddings', 
        'search_sessions',
        'content_embeddings',
        'legal_documents'
      ];

      for (const table of tables) {
        try {
          await this.client`DROP TABLE IF EXISTS ${this.client(table)} CASCADE`;
          console.log(`üóëÔ∏è Dropped table: ${table}`);
        } catch (error: any) {
          console.warn(`‚ö†Ô∏è Warning dropping table ${table}:`, error.message);
        }
      }

      // Run migrations again
      const migrationResult = await this.runMigrations();
      
      if (migrationResult.success) {
        console.log('‚úÖ Database reset completed');
        return true;
      } else {
        console.error('‚ùå Database reset failed during migration');
        return false;
      }

    } catch (error: any) {
      console.error('‚ùå Database reset failed:', error);
      return false;
    }
  }

  /**
   * Backup database
   */
  async backupDatabase(): Promise<string | null> {
    try {
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const backupName = `legal_ai_backup_${timestamp}`;

      console.log(`üíæ Creating database backup: ${backupName}`);

      // In a production environment, you would use pg_dump
      // For now, we'll create a logical backup using SQL
      const backupQuery = `
        SELECT jsonb_build_object(
          'backup_name', '${backupName}',
          'timestamp', NOW(),
          'tables', jsonb_build_object(
            'legal_documents', (SELECT jsonb_agg(row_to_json(t)) FROM legal_documents t),
            'content_embeddings', (SELECT jsonb_agg(row_to_json(t)) FROM content_embeddings t),
            'search_sessions', (SELECT jsonb_agg(row_to_json(t)) FROM search_sessions t),
            'embeddings', (SELECT jsonb_agg(row_to_json(t)) FROM embeddings t)
          )
        ) as backup_data
      `;

      const result = await this.client.unsafe(backupQuery);
      
      // In production, save to file or cloud storage
      const backupDir = path.join(__dirname, '../backups');
      await fs.mkdir(backupDir, { recursive: true });
      
      const backupFile = path.join(backupDir, `${backupName}.json`);
      await fs.writeFile(backupFile, JSON.stringify(result[0].backup_data, null, 2));

      console.log(`‚úÖ Backup completed: ${backupFile}`);
      return backupName;

    } catch (error: any) {
      console.error('‚ùå Backup failed:', error);
      return null;
    }
  }

  /**
   * Get database statistics
   */
  async getDatabaseStats(): Promise<any> {
    try {
      const stats = await this.client`
        SELECT 
          schemaname,
          tablename,
          n_live_tup as row_count,
          n_dead_tup as dead_rows,
          pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size
        FROM pg_stat_user_tables
        WHERE schemaname = 'public'
        ORDER BY n_live_tup DESC
      `;

      const indexStats = await this.client`
        SELECT 
          schemaname,
          tablename,
          indexname,
          idx_tup_read,
          idx_tup_fetch
        FROM pg_stat_user_indexes
        WHERE schemaname = 'public'
        ORDER BY idx_tup_read DESC
      `;

      return {
        tables: stats,
        indexes: indexStats,
        generated_at: new Date().toISOString()
      };

    } catch (error: any) {
      console.error('‚ùå Failed to get database stats:', error);
      return null;
    }
  }

  // Private helper methods

  private async validateConnection(): Promise<void> {
    try {
      await this.client`SELECT 1`;
      console.log('‚úÖ Database connection validated');
    } catch (error: any) {
      throw new Error(`Database connection failed: ${error.message}`);
    }
  }

  private async runCustomMigrations(): Promise<void> {
    try {
      const migrationsDir = path.join(__dirname, '../drizzle');
      const files = await fs.readdir(migrationsDir);
      const sqlFiles = files.filter(file => file.endsWith('.sql'));

      for (const file of sqlFiles) {
        const filePath = path.join(migrationsDir, file);
        const sql = await fs.readFile(filePath, 'utf-8');
        
        console.log(`üìù Running custom migration: ${file}`);
        await this.client.unsafe(sql);
      }

    } catch (error: any) {
      console.warn('‚ö†Ô∏è Custom migrations warning:', error.message);
    }
  }

  private async validateTables(): Promise<boolean> {
    try {
      const requiredTables = [
        'legal_documents',
        'content_embeddings', 
        'search_sessions',
        'embeddings',
        'system_logs'
      ];

      const existingTables = await this.client`
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public'
      `;

      const tableNames = existingTables.map(row => row.table_name);
      const missingTables = requiredTables.filter(table => !tableNames.includes(table));

      if (missingTables.length > 0) {
        console.error(`‚ùå Missing tables: ${missingTables.join(', ')}`);
        return false;
      }

      console.log('‚úÖ All required tables exist');
      return true;

    } catch (error: any) {
      console.error('‚ùå Table validation error:', error);
      return false;
    }
  }

  private async validateIndexes(): Promise<boolean> {
    try {
      const indexes = await this.client`
        SELECT indexname 
        FROM pg_indexes 
        WHERE schemaname = 'public'
      `;

      const requiredIndexes = [
        'idx_legal_documents_document_type',
        'idx_legal_documents_jurisdiction',
        'idx_legal_documents_content_embedding',
        'idx_content_embeddings_content_id'
      ];

      const indexNames = indexes.map(row => row.indexname);
      const missingIndexes = requiredIndexes.filter(index => !indexNames.includes(index));

      if (missingIndexes.length > 0) {
        console.warn(`‚ö†Ô∏è Missing indexes: ${missingIndexes.join(', ')}`);
        // Don't fail validation for missing indexes, just warn
      }

      console.log('‚úÖ Index validation completed');
      return true;

    } catch (error: any) {
      console.error('‚ùå Index validation error:', error);
      return false;
    }
  }

  private async validateExtensions(): Promise<boolean> {
    try {
      const extensions = await this.client`
        SELECT extname 
        FROM pg_extension
      `;

      const extensionNames = extensions.map(row => row.extname);
      const hasVector = extensionNames.includes('vector');
      const hasUuid = extensionNames.includes('uuid-ossp');

      if (!hasVector) {
        console.warn('‚ö†Ô∏è pgvector extension not found - vector operations may not work');
      }

      if (!hasUuid) {
        console.warn('‚ö†Ô∏è uuid-ossp extension not found - UUID generation may not work');
      }

      console.log('‚úÖ Extension validation completed');
      return true; // Don't fail for missing extensions

    } catch (error: any) {
      console.error('‚ùå Extension validation error:', error);
      return false;
    }
  }

  private async validateDataIntegrity(): Promise<boolean> {
    try {
      // Check for basic data integrity
      const documentCount = await this.client`SELECT COUNT(*) FROM legal_documents`;
      console.log(`üìä Legal documents: ${documentCount[0].count}`);

      const embeddingCount = await this.client`SELECT COUNT(*) FROM content_embeddings`;
      console.log(`üìä Content embeddings: ${embeddingCount[0].count}`);

      console.log('‚úÖ Data integrity validation completed');
      return true;

    } catch (error: any) {
      console.error('‚ùå Data integrity validation error:', error);
      return false;
    }
  }

  async close(): Promise<void> {
    await this.client.end();
  }
}

// CLI interface for running migrations
async function main() {
  const args = process.argv.slice(2);
  const command = args[0];

  const migrationRunner = new DatabaseMigrationRunner();

  try {
    switch (command) {
      case 'migrate':
        await migrationRunner.createDatabase();
        const migrationResult = await migrationRunner.runMigrations();
        console.log('Migration result:', migrationResult);
        break;

      case 'validate':
        const validationResult = await migrationRunner.validateDatabase();
        console.log('Validation result:', validationResult);
        break;

      case 'reset':
        const resetResult = await migrationRunner.resetDatabase();
        console.log('Reset result:', resetResult);
        break;

      case 'backup':
        const backupName = await migrationRunner.backupDatabase();
        console.log('Backup name:', backupName);
        break;

      case 'stats':
        const stats = await migrationRunner.getDatabaseStats();
        console.log('Database stats:', JSON.stringify(stats, null, 2));
        break;

      case 'test-setup':
        const testSetup = await migrationRunner.setupTestDatabase();
        console.log('Test setup result:', testSetup);
        break;

      default:
        console.log(`
Usage: node migration-runner.js <command>

Commands:
  migrate     - Run database migrations
  validate    - Validate database schema
  reset       - Reset database (drop and recreate)
  backup      - Create database backup
  stats       - Show database statistics
  test-setup  - Setup test database

Examples:
  node migration-runner.js migrate
  node migration-runner.js validate
  node migration-runner.js backup
        `);
    }

  } catch (error) {
    console.error('‚ùå Command failed:', error);
    process.exit(1);
  } finally {
    await migrationRunner.close();
  }
}

// Export for use in other modules
export { DatabaseMigrationRunner };

// Run CLI if this file is executed directly
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}
